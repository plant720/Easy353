#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time       : 2022/4/6 4:59 下午
# @Author     : zzhen
# @File       : assembly.py
# @Software   : PyCharm
# @Description:
# @Copyright  : Copyright (c) 2022 by sculab, All Rights Reserved.
import os
from shutil import rmtree
import argparse
import collections

# import my python file
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import partial
from Easy353Lib.utils import make_ref_kmer_dict, get_seq_avg_length, reverse_complement_limit, \
    get_reads_info, get_file_list, log


# get the median of a list
def get_median(lst: list) -> float:
    lst.sort()
    half = len(lst) // 2
    return (lst[half] + lst[~half]) / 2


# kmers generator
def make_kmers(seq, k):
    for i in range(len(seq) - k + 1):
        yield seq[i:i + k]


# Get all possible candidate nodes for a given kmer
def forward(seq):
    for x in 'ACGT':
        yield seq[1:] + x


def reverse(seq):
    for x in 'TGCA':
        yield x + seq[:-1]


# divide the read into kmer: return a read_kmer_dict
# read_kmer_dict: key:read_kmer value:[read_count,read_pos]
# _read_file_list_: List of sequencing files for assembly
# _ref_kmer_dict_: the kmer dictionary of reference sequence
def make_assemble_hash_dict(_read_file_: str, _ref_file_: str, _kmer_size_: int,
                            _ref_reverse_complement_: bool = False, _read_reverse_complement_: bool = False,
                            _pos_: bool = True, _print_: bool = True) -> tuple:
    # Get the seed dictionary from the reference file
    _ref_kmer_dict_ = make_ref_kmer_dict(_ref_file_, _kmer_size_, _ref_reverse_complement_, _pos_,
                                         _print_=False)
    # get the avg_len of the reference files
    _ref_avg_length = get_seq_avg_length(_ref_file_)
    read_kmer_dict = collections.defaultdict(list)
    infile = open(_read_file_, 'r', encoding='utf-8', errors='ignore')
    infile.readline()
    for line in infile:
        temp_str = []
        while line and line[0] != '>':
            temp_str.append(line)
            line = infile.readline()
        _read_seq_ = ''.join(filter(str.isalnum, ''.join(temp_str).upper()))
        # the reads are already paired, not need to reverse and complement the reads
        reads_seqs = [_read_seq_]
        if _read_reverse_complement_:
            reads_seqs.append(reverse_complement_limit(_read_seq_))
        for _seq_ in reads_seqs:
            # used to identify whether the kmer generated by the current read is in the reference sequence,
            # if a kmer is in the reference sequence, then flag is set to true and record the position information.
            kmer_flag = False
            # represent the distance pos_int from the last recorded kmer, the distance temp_pos of the current kmer
            pos_list = [1, 0]
            for j in range(0, len(_seq_) - _kmer_size_ + 1):
                kmer_info_list, read_kmer = [], _seq_[j:j + _kmer_size_]
                if read_kmer in read_kmer_dict:
                    read_kmer_dict[read_kmer][0] += 1
                else:
                    # Whenever a kmer generated by a read appears in kmer_dict, the kmer information is recorded uniformly
                    # Sum of position in ref_dict / total number of occurrences in ref_dict
                    if read_kmer in _ref_kmer_dict_:
                        # On the reverse complementary sequence of the reference sequence
                        if _ref_kmer_dict_[read_kmer][1] < 0:
                            pos_list[1] = 1 + _ref_kmer_dict_[read_kmer][1] / _ref_kmer_dict_[read_kmer][0]
                        else:
                            pos_list[1] = _ref_kmer_dict_[read_kmer][1] / _ref_kmer_dict_[read_kmer][0]
                        kmer_flag = True
                    else:
                        if kmer_flag:
                            pos_list[1] += pos_list[0] / _ref_avg_length
                    # When a kmer is neither in the reference sequence nor kmer_flag is true, then the position information is 0
                    kmer_info_list = [1, pos_list[1]]
                    read_kmer_dict[read_kmer] = kmer_info_list
    infile.close()
    return read_kmer_dict, _ref_kmer_dict_


# temp_list:  Store the kmer used for assembly, each time the last kmer is popped up, used for extension
# reads_list: Store the kmer used for assembly
# stack_list: stack Kmer is recorded as a node, using the method of traversing a tree,
#   backtracking to the last divergent node every time you get to a leaf node until the stack is empty (recorded when a divergence occurs)
# best_kmc: Record the maximum cumulative node weight value
# cur_kmc: Record the current cumulative node weight value
# best_pos: record the best pos
# cur_pos: current pos
# best_seq: record the best path
# cur_seq: record the current path
def assemble_contig_forward(_read_kmer_dict_: dict, _seed_: str, iteration: int = 1000) -> tuple:
    temp_list, stack_list = [_seed_], []
    best_kmer_weight, cur_kmer_weight, best_seq, cur_seq, best_pos, cur_pos = [], [], [], [], [], []
    # Initialize a set and each element is a tuple
    # The first element is the kmer used for assembly, and the second element is the number of kmer
    used_kmer_info = {(_seed_, _read_kmer_dict_.get(_seed_)[0])}
    _pos, node_distance = 0, 0
    while True:
        # Dynamically generate the kmers for the next iteration and rank them according to the weights
        node = sorted(
            [(i, _read_kmer_dict_[i][1], count_pos(_read_kmer_dict_[i][0], _pos, _read_kmer_dict_[i][1]),
              _read_kmer_dict_[i][0]) for i
             in forward(temp_list[-1])
             if i in _read_kmer_dict_], key=lambda _: _[2], reverse=True)
        while node:
            if node[0][0] in temp_list:
                node.pop(0)
            else:
                break
        if not node:
            iteration -= 1
            if sum(cur_kmer_weight) > sum(best_kmer_weight):
                best_kmer_weight, best_seq, best_pos = cur_kmer_weight.copy(), cur_seq.copy(), cur_pos.copy()
            [(temp_list.pop(), cur_kmer_weight.pop(), cur_seq.pop(), cur_pos.pop()) for _ in range(node_distance)]
            if stack_list:
                node, node_distance, _pos = stack_list.pop()
            else:
                break
        if len(node) >= 2:
            # Put into stack_list, which can be used for backtracking in the next iteration
            stack_list.append((node[1:], node_distance, _pos))
            node_distance = 0
        if node[0][1] > 0:
            _pos = node[0][1]
        temp_list.append(node[0][0])
        cur_pos.append(node[0][1])
        cur_kmer_weight.append(node[0][2])
        cur_seq.append(node[0][0][-1])
        # When calculating the number of used kmer, the number of backtracked kmer is not removed
        used_kmer_info.add((node[0][0], node[0][3]))
        node_distance += 1
        if not iteration:
            break
    reads_list = [i[0] for i in used_kmer_info]
    cur_used_kmer_count = [i[1] for i in used_kmer_info]
    return best_seq, best_pos, reads_list, sum(cur_used_kmer_count)


# Calculate weights using kmer's occurrence and location information
def count_pos(count, cur_pos, average_pos):
    if cur_pos and average_pos:
        return count ** float(1 - abs(cur_pos - average_pos))
    return count ** 0.5


def assemble_read_for_contig(_read_kmer_dict_: dict, _seed_: str, iteration: int = 1000):
    right, pos_1, reads_list_1, kmer_count_1 = \
        assemble_contig_forward(_read_kmer_dict_, _seed_, iteration)
    left, pos_2, reads_list_2, kmer_count_2 = \
        assemble_contig_forward(_read_kmer_dict_, reverse_complement_limit(_seed_), iteration)
    _pos_all_ = [x for x in pos_1 + pos_2 if x > 0]
    min_pos, max_pos = 0, 1
    if _pos_all_:
        min_pos, max_pos = min(_pos_all_), max(_pos_all_)
    return (reverse_complement_limit(''.join(left)) + _seed_ + ''.join(right),
            min_pos, max_pos, reads_list_1 + reads_list_2, len(set(reads_list_1 + reads_list_2)),
            kmer_count_1 + kmer_count_2)


def get_scaffold(_read_kmer_dict_: dict, _seed_: list, _kmer_limit_count_: int, gene_avg_len: int,
                 iteration: int = 1000) -> str:
    # First, assemble to produce a contig
    mid_seed, min_dis = _seed_[0], 1
    # Returns a tuple (a contig,reads_list containing all the reads used for assembly)
    contig, min_pos, max_pos, read_list, _, _ = assemble_read_for_contig(_read_kmer_dict_, mid_seed[0], iteration)
    for i in read_list:
        if i in _read_kmer_dict_:
            del _read_kmer_dict_[i]
    contigs = [(contig, min_pos, max_pos)]
    _left_seed_ = tuple()

    # one element in _seed_ is a tuple (_kmer_,_count_,avg_pos)
    for x in _seed_[1:]:
        # Select the seed that appears to the left of the contig for assembling the contigs
        if x[2] < min_pos and x[1] > _kmer_limit_count_:
            _left_seed_ = x
    while _left_seed_:
        contig, _min_pos, _max_pos, read_list, _, _ = assemble_read_for_contig(_read_kmer_dict_, _left_seed_[0],
                                                                               iteration)
        for i in read_list:
            if i in _read_kmer_dict_:
                del _read_kmer_dict_[i]
        if _left_seed_[2] < _min_pos or _left_seed_[2] > _max_pos:
            break
        # print(_min_pos, _max_pos,contig)
        if _max_pos < contigs[0][2]:
            contigs.insert(0, (contig, _min_pos, _max_pos))
        else:
            break
        _left_seed_ = tuple()
        for x in _seed_:
            if x[2] < _min_pos and x[1] > _kmer_limit_count_:
                _left_seed_ = x
    _right_seed_ = tuple()
    for x in _seed_:
        # select the seed that appears to the right of the contig for assembling the contigs
        if x[2] > max_pos and x[1] > _kmer_limit_count_:
            _right_seed_ = x
    while _right_seed_:
        contig, _min_pos, _max_pos, read_list, _, _ = assemble_read_for_contig(_read_kmer_dict_, _right_seed_[0],
                                                                               iteration)
        for i in read_list:
            if i in _read_kmer_dict_:
                del _read_kmer_dict_[i]
        if _right_seed_[2] < _min_pos or _right_seed_[2] > _max_pos:
            break
        # print(_min_pos, _max_pos, contig)
        if _min_pos > contigs[-1][1]:
            contigs.append((contig, _min_pos, _max_pos))
        else:
            break
        _right_seed_ = tuple()
        for x in _seed_:
            if x[2] > _max_pos and x[1] > _kmer_limit_count_:
                _right_seed_ = x
    scaffold = contigs[0][0]
    for x in range(1, len(contigs)):
        scaffold += max(2, int((contigs[x][1] - contigs[x - 1][2]) * gene_avg_len)) * 'N' + contigs[x][0]
    return scaffold


# When do the assembly, the reference sequence needs to be reverse-complementary
# This is because the seeds selected  the are reverse-complementary,
# and when the reference sequence is not reverse-complementary, an error will be reported
def assemble_one_file(_reads_file_: str, _out_dir_: str, _ref_file_: str,
                      _assemble_kmer_size_: int, _ref_reverse_complement_: bool = True,
                      _pos_: bool = True, _change_seed_: int = 1000, _kmer_limit_count_: int = 2,
                      _min_percent_length_: float = 0.5, _max_percent_length_: float = 1.5,
                      _iteration_: int = 1000, _print_: bool = True) -> dict:
    assemble_gene_info_dict = collections.defaultdict(dict)
    # set output file name
    gene_name = os.path.basename(_ref_file_).split(".")[0]
    target_file_name = gene_name + ".target.fasta"
    unrecovered_dir = os.path.join(_out_dir_, "unrecovered_genes")

    # Get the average length of the gene and the number of sequences in the ref
    ref_seq_count, ref_seq_length = get_reads_info(_ref_file_)
    gene_avg_len = round(ref_seq_length / ref_seq_count, 2)

    _contig_path_ = os.path.join(_out_dir_, target_file_name)
    _short_contig_path_ = os.path.join(unrecovered_dir, target_file_name)

    assemble_success_flag = False
    is_normal_contig = False
    gene_info = {"assemble_success_flag": assemble_success_flag, "target_gene_length": 0, "unrecovered_gene_length": 0,
                 "filter_reads_count": 0, "kmer_usage_rate": 0,
                 "seed": "", "assemble_kmer_size": _assemble_kmer_size_,
                 "kmer_limit": _kmer_limit_count_, "contig_coverage_depth": 0, "ref_avg_length": gene_avg_len}
    assemble_gene_info_dict[gene_name] = gene_info
    if _print_:
        print("Assembling the {} gene".format(gene_name))
    # Returns False when the read file does not exist
    if not os.path.isfile(_reads_file_):
        print("Reads file of {} gene doesn't exist".format(gene_name))
        return assemble_gene_info_dict

    # make read_kmer_dict and ref_kmer_dict
    _read_kmer_dict_, _ref_kmer_dict_ = make_assemble_hash_dict(_reads_file_, _ref_file_, _assemble_kmer_size_,
                                                                _ref_reverse_complement_, True, _pos_, _print_=False)

    if not _read_kmer_dict_:
        # When read_kmer_dict is 0, it is assumed that _short_contig_path_ produces an empty file
        with open(_short_contig_path_, 'w'):
            pass
        print("Reads file of {} gene doesn't have enough reads".format(gene_name))
        return assemble_gene_info_dict

    # Based on the number of occurrences of kmer and whether it is in reference
    # delete the kmer with low number of occurrences
    if _kmer_limit_count_ > 0:
        # delete kmer with low number of occurrences and not in reference
        _filter_ = [_kmer_ for _kmer_ in _read_kmer_dict_ if _read_kmer_dict_[_kmer_][0] <= _kmer_limit_count_]
        for _kmer_ in _filter_:
            if _read_kmer_dict_[_kmer_][1] == 0:
                del _read_kmer_dict_[_kmer_]
        # clean memory
        del _filter_

    # get the number of kmer
    filter_reads_count, _ = get_reads_info(_reads_file_)

    # Set the weight of the seed, Select the kmer that exists in both read and ref
    shared_seed = [x for x in _ref_kmer_dict_ if x in _read_kmer_dict_]
    ref_kmer_count = [_ref_kmer_dict_[i][0] for i in shared_seed]
    read_kmer_count = [_read_kmer_dict_[i][0] for i in shared_seed]

    seed_list = [(x, _ref_kmer_dict_[x][0] / get_median(ref_kmer_count) * _read_kmer_dict_[x][0]
                  / get_median(read_kmer_count), _ref_kmer_dict_[x][1] / _ref_kmer_dict_[x][0]) for x in shared_seed]
    # Calculate the total number of remaining kmer after removing the less frequent kmer
    read_kmer_count_sum = sum(_read_kmer_dict_[i][0] for i in _read_kmer_dict_)
    del shared_seed, ref_kmer_count, read_kmer_count

    # Sorting according to kmer weights
    list.sort(seed_list, key=lambda x: x[1], reverse=True)
    if not seed_list:
        with open(_short_contig_path_, 'w'):
            pass
        print("The ref file of {} gene does not have enough sequences".format(gene_name))
        return assemble_gene_info_dict

    # Select the most frequently occurring _kmer_ as the starting seed
    # unique_kmer_number Calculating the number of different kmer
    # used_kmer_count The sum of the occurrences of kmer used
    _cur_seed_info_ = seed_list[0]
    contig, _, _, _, unique_kmer_number, used_kmer_count = \
        assemble_read_for_contig(_read_kmer_dict_, _cur_seed_info_[0], _iteration_)

    # Record the longest contig
    best_contig = contig
    best_kmer_count = used_kmer_count
    best_unique_kmer_number = unique_kmer_number
    best_seed_seq = _cur_seed_info_[0]

    short_contig_length = 0
    contig_length = 0
    # If the sequence is too short, the strategy is to replace the seed
    if len(contig) / gene_avg_len < _min_percent_length_:
        # Record current contig and kmer related information
        change_count = 0
        last_seed_info = _cur_seed_info_
        # select a seed from seed_list
        for new_seed_info in seed_list[1:]:
            # Do not select kmer that have 1-2bp overlap with the current seed
            if last_seed_info[0][1:] == new_seed_info[0][:-1] or last_seed_info[0][2:] == new_seed_info[0][:-2]:
                last_seed_info = new_seed_info
                continue
            # record the seed
            last_seed_info = new_seed_info
            # generate a new contig
            contig, _, _, _, unique_kmer_number, used_kmer_count = \
                assemble_read_for_contig(_read_kmer_dict_, new_seed_info[0], _iteration_)
            change_count += 1
            # If the new contig is longer than the previously stored best_contig,
            # the information of the record will be changed
            if len(contig) > len(best_contig):
                best_contig, best_seed_seq, best_unique_kmer_number, best_kmer_count = \
                    contig, new_seed_info[0], unique_kmer_number, used_kmer_count
            if len(best_contig) / gene_avg_len >= _min_percent_length_ or change_count >= int(_change_seed_):
                break

        # When the obtained best_contig length reaches the target,is_normal_contig:True assemble_success_flag:True
        if len(best_contig) / gene_avg_len >= _min_percent_length_:
            contig_length = len(best_contig)
            is_normal_contig = True
            assemble_success_flag = True
        else:
            short_contig_length = len(best_contig)
    # If the contig is too long, increase _kmer_limit_count_
    elif len(contig) / gene_avg_len > _max_percent_length_:
        is_normal_contig = True
        assemble_success_flag = True
        # increase limit
        for temp_kmer_limit in range(_kmer_limit_count_ + 1, 32):
            _filter_ = [x for x in _read_kmer_dict_ if _read_kmer_dict_[x][0] <= temp_kmer_limit]
            for x in _filter_:
                if _read_kmer_dict_[x][1] == 0:
                    del _read_kmer_dict_[x]
            del _filter_
            contig, _, _, _, unique_kmer_number, used_kmer_count \
                = assemble_read_for_contig(_read_kmer_dict_, _cur_seed_info_[0])
            if _max_percent_length_ >= len(contig) / gene_avg_len >= _min_percent_length_:
                best_contig, best_unique_kmer_number, best_kmer_count = contig, unique_kmer_number, used_kmer_count
                break
            # When increasing _kmer_limit_count_, if the sequence is lower than the standard, the current best_contig is selected.
            elif len(contig) / gene_avg_len < _min_percent_length_:
                break
            # When the sequence is still long after increasing _kmer_limit_count_, the current optimal contig is replaced.
            else:
                best_contig, best_unique_kmer_number, best_kmer_count = contig, unique_kmer_number, used_kmer_count
        contig_length = len(best_contig)
    else:
        contig_length = len(best_contig)
        is_normal_contig = True
        assemble_success_flag = True

    if is_normal_contig:
        if _print_:
            print("Assemble {} gene succeed. Ref length: {}, best contig length: {}.".format
                  (gene_name, gene_avg_len, len(best_contig)))
        with open(_contig_path_, 'w') as out:
            out.write(
                '>' + _out_dir_.split("/")[-2] + "_" + gene_name + '_recovered_k' + str(_assemble_kmer_size_) +
                "_" + str(len(best_contig)) + '\n')
            out.write(best_contig + '\n')
    else:
        if _print_:
            print("Assemble {} gene failed. Ref length: {}, best contig length: {}.".format
                  (gene_name, gene_avg_len, len(best_contig)))
        with open(_short_contig_path_, 'w') as out:
            out.write('>' + _out_dir_.split("/")[-2] + "_" + gene_name + '_unrecovered_k' +
                      str(_assemble_kmer_size_) + "_" + str(len(best_contig)) + '\n')
            out.write(best_contig + '\n')

    # contig coverage: used_kmer_count*kmer_size / unique_kmer_count
    contig_coverage_depth = round(best_kmer_count * _assemble_kmer_size_ / best_unique_kmer_number, 2)

    gene_info["assemble_success_flag"] = assemble_success_flag
    gene_info["target_gene_length"] = contig_length
    gene_info["unrecovered_gene_length"] = short_contig_length
    gene_info["filter_reads_count"] = filter_reads_count
    gene_info["kmer_usage_rate"] = round(best_kmer_count / read_kmer_count_sum, 2)
    gene_info["seed"] = best_seed_seq
    gene_info["contig_coverage_depth"] = contig_coverage_depth
    assemble_gene_info_dict[gene_name] = gene_info
    return assemble_gene_info_dict


def assemble_flow(_input_read_path_: str, _out_dir_: str, _ref_path_: str, _assemble_kmer_size_: int,
                  _assemble_thread_: int = 4, _ref_reverse_complement_: bool = True, _pos_: bool = True,
                  _change_seed_: int = 1000, _kmer_limit_count_: int = 2, _min_percent_length_: float = 1.0,
                  _max_percent_length_: float = 2.0, _iteration_: int = 1000):
    assemble_out_dir = os.path.join(_out_dir_, "target_genes")
    if not os.path.isdir(assemble_out_dir):
        os.makedirs(assemble_out_dir)
    else:
        rmtree(assemble_out_dir)
        os.makedirs(assemble_out_dir)
    if not os.path.isdir(os.path.join(assemble_out_dir, "unrecovered_genes")):
        os.makedirs(os.path.join(assemble_out_dir, "unrecovered_genes"))

    print('Assemble reads')
    file_dict = collections.defaultdict(dict)
    for ref_file_path in get_file_list(_ref_path_):
        gene_name = os.path.basename(ref_file_path).split(".")[0]
        file_dict[gene_name]["ref_file"] = ref_file_path
        if os.path.isdir(_input_read_path_) and os.path.isfile(os.path.join(_input_read_path_, gene_name + ".fasta")):
            file_dict[gene_name]["reads_file"] = os.path.join(_input_read_path_, gene_name + ".fasta")
        elif os.path.isfile(_input_read_path_) and gene_name in _input_read_path_:
            file_dict[gene_name]["reads_file"] = _input_read_path_
        else:
            file_dict[gene_name]["reads_file"] = None
    # Used to store information on whether the gene was filtered successfully or not
    assemble_gene_info_dict = collections.defaultdict(dict)
    count = 0
    with ThreadPoolExecutor(max_workers=min(_assemble_thread_, len(file_dict))) as executor:
        futures = [executor.submit(
            partial(assemble_one_file, _out_dir_=assemble_out_dir, _assemble_kmer_size_=_assemble_kmer_size_,
                    _ref_reverse_complement_=_ref_reverse_complement_, _pos_=_pos_,
                    _change_seed_=_change_seed_, _kmer_limit_count_=_kmer_limit_count_,
                    _min_percent_length_=_min_percent_length_, _max_percent_length_=_max_percent_length_,
                    _iteration_=_iteration_),
            _reads_file_=file_info["reads_file"], _ref_file_=file_info["ref_file"])
            for gene_name, file_info in file_dict.items()]
        for future in as_completed(futures):
            assemble_gene_info_dict.update(future.result())
            count += 1
            if count % 10 == 0:
                print("INFO: {} / {} genes have been assembled!".format(count, len(file_dict)))

    assemble_flag_list = [i["assemble_success_flag"] for i in assemble_gene_info_dict.values()]
    print("Assemble Done! {} / {} succeed".format(assemble_flag_list.count(True), len(assemble_flag_list)))
    # log
    log_file = os.path.join(assemble_out_dir, "assemble_log.csv")
    log(log_file, "gene_id", "ref_avg_length", "target_gene_length", "unrecovered_gene_length", "contig_coverage_depth",
        "assemble_kmer", "assemble_seed", "kmer_limit", "filter_reads_count",
        "kmer_usage_rate")
    for gene_name, gene_info in assemble_gene_info_dict.items():
        log(log_file, gene_name, gene_info["ref_avg_length"], gene_info["target_gene_length"],
            gene_info["unrecovered_gene_length"],
            gene_info["contig_coverage_depth"], gene_info["assemble_kmer_size"],
            gene_info["seed"], gene_info["kmer_limit"], gene_info["filter_reads_count"],
            gene_info["kmer_usage_rate"])
    return assemble_gene_info_dict


if __name__ == "__main__":
    pars = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description='''Miner
    zzhen@sculab ''')
    pars.add_argument('-i', dest='input_dir', help='Input a file(directory) with reads data', required=True)
    pars.add_argument("-r", dest="reference", type=str, help="Input a file(directory) with references", required=True)
    pars.add_argument("-o", dest="output_dir", type=str, help="Output directory.", required=False,
                      default="easy353_output")
    pars.add_argument("-k", dest="assemble_kmer", type=int, help="Kmer setting for assembling reads. Default:41",
                      default=41)
    pars.add_argument("-s", dest="step_length", type=int,
                      help="Step length of the sliding window on the reads. Default:1", default=1)
    pars.add_argument("-t", dest="assemble_thread", type=int,
                      help="Threads setting for assembling reads. Default:4", default=4)
    pars.add_argument("-kmer_limit", dest="kmer_limit", type=int, help="Limit of kmer count. Default:3", default=2)
    pars.add_argument("-min", dest="minimum_length_ratio", type=float,
                      help="The minimum ratio of contig length to reference average length. Default:1.0", default=1.0)
    pars.add_argument("-max", dest="maximum_length_ratio", type=float,
                      help="The maximum ratio of contig length to reference average length. Default:2.0", default=2.0)
    pars.add_argument("-change_seed", dest="change_seed", type=int, help="Times of changing seed. Default:32",
                      default=32)
    pars.add_argument("-fast", dest="fast", action="store_true", help="Whether to use fast mode.")
    pars.add_argument("-reference_number", dest="reference_number", type=int,
                      help="The number of the reference sequences used to build hash table. Default:all", default=None)
    args = pars.parse_args()

    assemble_flow(_input_read_path_=args.input_dir, _out_dir_=args.output_dir, _ref_path_=args.reference,
                  _assemble_kmer_size_=args.assemble_kmer,
                  _assemble_thread_=args.assemble_thread, _ref_reverse_complement_=True, _pos_=True,
                  _change_seed_=args.change_seed, _kmer_limit_count_=args.kmer_limit,
                  _min_percent_length_=args.minimum_length_ratio, _max_percent_length_=args.maximum_length_ratio,
                  _iteration_=1000)
